# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14vncosIkUOmzg4N3PtDfExqCsFtyWG7k

1. MENGUMPULKAN DATA
"""

#PENGUMPULAN DATA
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/MyDrive/water_potability.csv')
df.head()

"""2. MENELAAH DATA"""

#MENELAAH DATA
df.shape #mengetahui baris dan kolom
df.info() #informasi data

#menampilkan nilai unik
for col in df.columns :
  print(f"nilai unik {col} has {df[col].unique()}")

"""3. VALIDASI DATA"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

#CEK OUTLIER
#target
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns

#barplot outlier
plt.figure(figsize=(12, 8))
sns.barplot(df[numerical_cols])
plt.title("Bar Plot untuk Deteksi Outlier")
plt.show()

#cek missing value
df.isna().sum().sort_values(ascending=False) #menampilkan data kosong atau hilang

#kolom yang memiliki missing value
missing_value = ['Sulfate', 'ph', 'Trihalomethanes']

# Imputasi mean
for col in missing_value:
    df[col].fillna(df[col].mean(), inplace=True)

#cek ulang
print(df[missing_value].isnull().sum())

# Distribusi data sebelum
print(df['Potability'].value_counts())
#countplot->barplot untuk distribusi data
plt.figure(figsize=(6, 4))
sns.countplot(x='Potability', data=df)
plt.title('Distribusi Data Kualitas Air (Sebelum Resampling)')
plt.xlabel('Potability')
plt.ylabel('Jumlah')
plt.show()

#oversampling dengan SMOTE
from imblearn.over_sampling import SMOTE

# Pisahkan fitur dan target
X = df.drop('Potability', axis=1)
y = df['Potability']

# Inisialisasi
smote = SMOTE(random_state=42)

# oversampling
X_resampled, y_resampled = smote.fit_resample(X, y)

# Buat DataFrame baru
df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled['Potability'] = y_resampled

# Distribusi data setelah
print(df_resampled['Potability'].value_counts())
#countplot->barplot untuk distribusi data
plt.figure(figsize=(6, 4))
sns.countplot(x='Potability', data=df_resampled)
plt.title('Distribusi Data Kualitas Air (Setelah Resampling)')
plt.xlabel('Potability')
plt.ylabel('Jumlah')
plt.show()

"""4. MENENTUKAN OBJECT"""

#menentukan objek => potability
#pisahkan fitur dan target
X = df_resampled.drop('Potability', axis=1)  # Fitur
y = df_resampled['Potability']  # Target

"""5. CLEANING DATA

"""

#buat korelasi heatmap
corr_heat=df_resampled.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr_heat,annot=True,cmap='coolwarm')
plt.show()

#buat distribusi histogram plot
df_resampled.hist(figsize=(10,10))
plt.show()

#cek nilai kosong
df_resampled.isna().sum()

#cek nilai duplikat
df_resampled.duplicated().sum()

"""6. KONSTRUKSI DATA"""

#konstruksi data
df_resampled.info()

df_resampled.describe()

df_resampled.head()

"""Data sudah sesuai

7. PEMODELAN
"""

#bagi data 70:30 latih dan uji
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.30, random_state=42)

#pemodelan dengan knn
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#membuat model
knn = KNeighborsClassifier()

#latih model
knn.fit(X_train, y_train)

#confussion matrix
y_pred_knn = knn.predict(X_test)
cm = confusion_matrix(y_test, y_pred_knn)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['tidak stabil', 'stabi;'], yticklabels=['tidak stabil', 'stabil'])
plt.xlabel('predicted')
plt.ylabel('true')
plt.title('cmatrix')
plt.show()

#pemodelan dengan random forest classifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#membuat model
rf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 3)

#latih model
rf.fit(X_train, y_train)

#confussion matrix
y_pred_rf = rf.predict(X_test)
cmrf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8,6))
sns.heatmap(cmrf, annot=True, fmt='d', cmap='Blues', xticklabels=['tidak stabil', 'stabi;'], yticklabels=['tidak stabil', 'stabil'])
plt.xlabel('predicted')
plt.ylabel('true')
plt.title('cmatrix')
plt.show()

#pemodelan dengan ADABoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#membuat model
ada = AdaBoostClassifier()

#latih model
ada.fit(X_train, y_train)

#confusion matrix
y_pred_ada = ada.predict(X_test)
cmada = confusion_matrix(y_test, y_pred_ada)
plt.figure(figsize=(8,6))
sns.heatmap(cmada, annot=True, fmt='d', cmap='Blues', xticklabels=['tidak stabil', 'stabi;'], yticklabels=['tidak stabil', 'stabil'])
plt.xlabel('predicted')
plt.ylabel('true')
plt.title('cmatrix')
plt.show()

"""8. EVALUASI"""

#knn
print("\nKNN Model:")
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print("Accuracy:",accuracy_knn)
print("Classification Report:")
print(classification_report(y_test, y_pred_knn))

#random forest
print("\nRandom Forest Model:")
accuracy_rf =accuracy_score(y_test, y_pred_rf)
print("Accuracy:",accuracy_rf)
print("Classification Report:")
print(classification_report(y_test, y_pred_rf))

#Adaboost
print("\nAdaBoost Model:")
accuracy_ada = accuracy_score(y_test, y_pred_ada)
print("Accuracy:",accuracy_ada)
print("Classification Report:")
print(classification_report(y_test, y_pred_ada))

#compare 3 model
model = pd.DataFrame({
    'Model': ['KNN', 'RandomForest', 'AdaBoost'],
    'Akurasi':[accuracy_knn, accuracy_rf, accuracy_ada]
})

#urutkan
model.sort_values(by = 'Akurasi', ascending=False)

#visual
plt.figure(figsize=(10,6))
plt.barh(model['Model'],model['Akurasi'])
plt.xlabel('Akurasi')
plt.ylabel('Model')
plt.title('Komparasi')
plt.show()

#optimasi hyperparameter
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators' : [50, 100, 150, 200],
    'max_depth' : [None, 10, 20, 30],
    'min_samples_split' : [2,5,10],
    'min_samples_leaf' :[1,2,4],
    'max_features' : ['sqrt', 'log2', None],
    'criterion' : ['gini', 'entropy']
}

#init model
rf = RandomForestClassifier(random_state=42)

#setup Grid
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,cv=5, verbose=2, n_jobs=-1,scoring='accuracy')

#fit grid
grid_search.fit(X_train, y_train)

#perform terbaik
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Score: {grid_search.best_score_}")

from sklearn.model_selection import RandomizedSearchCV

# Definisikan ruang pencarian hyperparameter
param_dist = {
    'n_estimators': [50, 100, 150, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None],
    'criterion': ['gini', 'entropy']
}

# Inisialisasi model
rf = RandomForestClassifier(random_state=42)

# Setup RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=50,  # Jumlah iterasi
    cv=5,
    verbose=2,
    n_jobs=-1,
    scoring='accuracy'
)

# Fit RandomizedSearchCV
random_search.fit(X_train, y_train)

# Parameter dan skor terbaik
print(f"Parameter Terbaik: {random_search.best_params_}")
print(f"Skor Terbaik: {random_search.best_score_}")

"""KESIMPULAN


1.   RandomForestClassifier menjadi yang terbaik
2.   Optimasi hanya selisih sedikit
3.   RandomForestClassifier memiliki metode ensemble yang menggabungkan bberapa decision tree, dapat menangani missing value dengan baik, dan randomforest memiliki hubungan fitur dan target


"""